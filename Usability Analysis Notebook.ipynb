{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Model to Predict the Website perceived Usability "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Ibiyo Motunrayo O\n",
    "Usability is the extent to which a product can be used by specified user to achieve a specified goal with effectiveness, efficiency, and satisfaction in a specified context of use.\n",
    "\n",
    "This project uses data obtained from users to predict the users perceived usability. Furthermore this project aims to find the most significant features in the dataset that affects the prediction accuracy and Fbeta score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category = UserWarning, module = \"matplotlib\")\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "\n",
    "\n",
    "#\n",
    "# Display inline matplotlib plots with IPython\n",
    "from IPython import get_ipython\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "# Import supplementary visualization code visuals.py\n",
    "import visuals as vs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Journaldatapython.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('UsabilityIndex',1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explorative Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total number of records\n",
    "n_records = data.shape[0]\n",
    "\n",
    "#number of data with usability of user perceived usability that is yes\n",
    "yes_records = len(data[data['Class'] == 'Yes'])\n",
    "\n",
    "#number of data with usability of user perceived usability that is No\n",
    "no_records = len(data[data['Class'] == 'No'])\n",
    "\n",
    "yes_percent = (yes_records/n_records)*100\n",
    "\n",
    "print('Total number of records: {}'.format(n_records))\n",
    "print('Perceived usability with class Yes:{}'.format(yes_records))\n",
    "print('Perceived usability with class No:{}'.format(no_records))\n",
    "print ('percentage of perceived userbility of Yes class.{}'.format(yes_percent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FeatureSet Exploration**\n",
    "Gender: \n",
    "Male, Female\n",
    "Age range: \n",
    "under 16, 16 - 20, 21 - 25, 26 above\n",
    "Department: \n",
    "Computer Science, Project Management Technology, Chemistry, Information and Media Technology, Medicine and Surgery, Civil Engineering, Biochemistry, Electrical Electronics Engineering, estate management and valuation, Pharmacy, Law, Art, Agricultural Economics, Geology, Agricultural Extension and Rural Development,Microbiology, Political Science, Education, computer engineering, quantity surveying, Physics, soil science and land management, zoology,mathematics, Telecommunications Engineering, Water acquaculture and Fisheries Technology, Sociology, Building Technology, Statistics, Food science and technology, Psychology, crop science, medical laboratory sciences, Library and Information Science, Entreprenuerial and Bussiness Studies, Criminology, Veterinary medicine, environmental studies, Information and Communication Technology, Mechanical Engineering, Economics, ITE\n",
    "Level: \n",
    "Undergraduate, Post graduate, others\t\n",
    "ComputerLiteracy: \n",
    "None, Novice, Intermediate, Expert\t\n",
    "University\n",
    "\n",
    "**Options**\n",
    "**1- Strongly disagree\n",
    "2- Disagree\n",
    "3 Neutral\n",
    "4-Agree\n",
    "5 Strongly agree **\n",
    "\n",
    "Speed (SP)\n",
    "SP1:-I need not wait too long to open a page\t\n",
    "SP2:-I am able to quickly complete my tasks using site. \n",
    "SP3:-I need not wait too long to download a file.\n",
    "Navigation\n",
    "NAV1:-I can easily navigate this site.\n",
    "NAV2:-I can easily know where I am at this website\n",
    "NAV3:-The website does not open too many new windows when I am moving around\t\n",
    "NAV4:-I don't need to scroll left or right on the website.\t\n",
    "Ease of use\n",
    "EU1:-The website is easy to use.\n",
    "EU2:-I can use the website without a guide.\n",
    "EU3:-The websites require few steps to accomplish tasks\t\n",
    "Content and Content Relevance\n",
    "CCR1:-The information provided on this website is sufficient for me.\n",
    "CCR2:-Content like academic news, publication date is up-to date.\n",
    "CCR3:-The website offers easy access to require details like contact nos., email address, postal address etc. of the university\n",
    "Accessibility\n",
    "ACC1:-The website provides alternative text presentation.\t\n",
    "ACC2:-The website is capable of full functionality via only keyboard.\t\n",
    "ACC3:-The navigation is designed to assist user in finding content and determine where they are\t\n",
    "Aesthetics and presentation\n",
    "AP1:-The website’s interface design is attractive.\n",
    "AP2:-The website has a clean and simple presentation.\t\n",
    "AP3:-I am comfortable with the colours used at this website.\t\n",
    "Reliability\n",
    "REL1:-The website is reachable exclusively over HTTPS. \t\n",
    "REL2:-The university’s website shows a warning message related to malicious software etc.\n",
    "\n",
    "\n",
    "UsabilityIndex: Continuous \n",
    "Class: No, Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section the raw data is cleaned and normalized for the learning algorithm. This section is very important as a clean data will increase the performance of the model. \n",
    "The following actions will be carried out on the dataset\n",
    "1. Removal of some features that could inhibit the goal of the prediction. e.g University and usability Index.\n",
    "   University is removed because the goal is to understand users perceived usability. \n",
    "   Usability Index increases the risk of making the problem to simple to solve, as a siumple rule using the usability index    alone might give an accuracy of 100%\n",
    "\n",
    "2. Derieve area of specialization from the feature department.\n",
    "3. The dataset is checked for the presence of null values.\n",
    "4. Convert Categorical Data to Numeric Data.\n",
    "   the classifying algorithms used in this project do not accept categorical data, it is preferred that data is in numeric form before passing it to the learning algorithm. In this step One hot Code, label Encoders and custom functions are used to convert categorical data to numeric.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the feature university from the dataset.\n",
    "data = data.drop('University', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_plot(column_name):\n",
    "    figure = plt.figure(10, figsize=(20, 4))\n",
    "    axs = figure.add_subplot(121)\n",
    "    axs.title.set_text('Bar Chart')\n",
    "    sns.countplot(data[column_name])\n",
    "    \n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_col = ['Gender', 'Age range', 'Department', 'Level', 'ComputerLiteracy',\n",
    "       'SP1', 'SP2', 'SP3', 'NAV1', 'NAV2', 'NAV3', 'NAV4',\n",
    "       'EU1', 'EU2', 'EU3', 'CCR1', 'CCR2', 'CCR3', 'ACC1', 'ACC2', 'ACC3',\n",
    "       'AP1', 'AP2', 'AP3', 'REL1', 'REL2', 'Class']\n",
    "\n",
    "for col in int_col:\n",
    "    count_plot(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "department = data['Department'].value_counts()\n",
    "\n",
    "department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def department_group (department):\n",
    "    #remove all leading spaces and lower the column\n",
    "    return department.lstrip().lower()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Department'] = data['Department'].apply(department_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_plot('Department')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discipline (department):\n",
    "    if department in ('computer science','electrical electronics engineering', 'engineering', 'information and media technology',\n",
    "                      'civil engineering', 'chemistry','computer engineering','electrical and electronics engineering',\n",
    "                    'statistics', 'mathematics', 'food science and technology','engineering','science', 'physics',\n",
    "                     'telecommunications engineering','mechanical engineering', 'information and communication technology',\n",
    "                    'criminology','microbiology' ):\n",
    "        return 'Science and Engineering'\n",
    "    elif department in ('geology','quantity surveying','estate management and valuation','soil science and land management',\n",
    "                       'zoology','agricultural economics','crop science','library and information science','environmental studies',\n",
    "                       'building','agricultural extension and rural development','water acquaculture and fisheries technology',\n",
    "                       ):\n",
    "        return 'Agricultural and Environmental Science'\n",
    "    elif department in ('medicine and surgery','pharmacy','biochemistry','dentistry and dental surgery','veterinary medicine',\n",
    "                       'medical laboratory sciences'):\n",
    "        return 'Medical Science'\n",
    "    else:\n",
    "        return 'Art,Social Science and Education'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Department'] = data['Department'].apply(discipline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "department = data['Department'].value_counts()\n",
    "\n",
    "department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_plot('Department')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OneHot code all fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Class',1) #Features that will be used for training the model\n",
    "y = data['Class'] #the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.fillna(0)\n",
    "X.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = pd.get_dummies(data = X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changes the 'yes' or 'no' on the ticket to 1 and 0 respectively\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelEncoder = LabelEncoder()\n",
    "y = labelEncoder.fit_transform(y)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size =0.2, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set has {} sample user response\". format(X_train.shape[0]))\n",
    "print(\"Test set has {} sample user response\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a training function\n",
    "from time import time\n",
    "from sklearn.metrics import fbeta_score, accuracy_score\n",
    "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test):\n",
    "    '''\n",
    "    inputs of the function:\n",
    "        - learner: the learning algorithm to be trained and predicted on\n",
    "        - sample_size: the size of samples to be drawn from the training set        \n",
    "        - X_train: Features for the training set\n",
    "        -y_train: usability for the training set\n",
    "        -X_test: features testing test\n",
    "        -y_test: income testing set\n",
    "    '''\n",
    "    results = {}\n",
    "    \n",
    "    #train the model\n",
    "    start = time()\n",
    "    learner = learner.fit(X_train[:sample_size],y_train[:sample_size])\n",
    "    end = time()\n",
    "    \n",
    "    results['train_time'] = end - start\n",
    "    \n",
    "       \n",
    "    #predict for test and training test\n",
    "    start = time()\n",
    "    prediction_test = learner.predict(X_test)\n",
    "    prediction_train = learner.predict(X_train[:sample_size])\n",
    "    end = time()\n",
    "    \n",
    "    results['pred_time'] = end - start\n",
    "    \n",
    "    results['acc_train'] = accuracy_score(y_train[:sample_size], prediction_train)\n",
    "    \n",
    "    results ['acc_test'] = accuracy_score (y_test, prediction_test)\n",
    "    \n",
    "    results['f_train'] = fbeta_score(y_train[:sample_size],prediction_train,0.5)\n",
    "    \n",
    "    results['f_test'] = fbeta_score(y_test,prediction_test, 0.5)\n",
    "    \n",
    "    #Success\n",
    "    print(\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
    "    \n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(results):\n",
    "    \"\"\"\n",
    "    Visualization code to display results of various learners.\n",
    "    \n",
    "    inputs:\n",
    "      - learners: a list of supervised learners\n",
    "      - stats: a list of dictionaries of the statistic results from 'train_predict()'\n",
    "      - accuracy: The score for the naive predictor\n",
    "      - f1: The score for the naive predictor\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(2, 3, figsize = (11,10))\n",
    "\n",
    "    # Constants\n",
    "    bar_width = 0.3\n",
    "    colors = ['#A00000','#00A0A0','#00A000']\n",
    "    \n",
    "    # Super loop to plot four panels of data\n",
    "    for k, learner in enumerate(results.keys()):\n",
    "        for j, metric in enumerate(['train_time', 'acc_train', 'f_train', 'pred_time', 'acc_test', 'f_test']):\n",
    "            for i in np.arange(3):\n",
    "                \n",
    "                # Creative plot code\n",
    "                ax[j//3, j%3].bar(i+k*bar_width, results[learner][i][metric], width = bar_width, color = colors[k])\n",
    "                ax[j//3, j%3].set_xticks([0.45, 1.45, 2.45])\n",
    "                ax[j//3, j%3].set_xticklabels([\"50%\", \"75%\", \"100%\"])\n",
    "                ax[j//3, j%3].set_xlabel(\"Training Set Size\")\n",
    "                ax[j//3, j%3].set_xlim((-0.3, 3.0))\n",
    "    \n",
    "    # Add unique y-labels\n",
    "    ax[0, 0].set_ylabel(\"Time (in seconds)\")\n",
    "    ax[0, 1].set_ylabel(\"Accuracy Score\")\n",
    "    ax[0, 2].set_ylabel(\"F-score\")\n",
    "    ax[1, 0].set_ylabel(\"Time (in seconds)\")\n",
    "    ax[1, 1].set_ylabel(\"Accuracy Score\")\n",
    "    ax[1, 2].set_ylabel(\"F-score\")\n",
    "    \n",
    "    # Add titles\n",
    "    ax[0, 0].set_title(\"Model Training\")\n",
    "    ax[0, 1].set_title(\"Accuracy Score on Training Subset\")\n",
    "    ax[0, 2].set_title(\"F-score on Training Subset\")\n",
    "    ax[1, 0].set_title(\"Model Predicting\")\n",
    "    ax[1, 1].set_title(\"Accuracy Score on Testing Set\")\n",
    "    ax[1, 2].set_title(\"F-score on Testing Set\")\n",
    "    \n",
    "    # Add horizontal lines for naive predictors\n",
    "    #ax[0, 1].axhline(y = accuracy, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
    "    #ax[1, 1].axhline(y = accuracy, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
    "    #ax[0, 2].axhline(y = f1, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
    "    #ax[1, 2].axhline(y = f1, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
    "    \n",
    "    # Set y-limits for score panels\n",
    "    ax[0, 1].set_ylim((0, 1))\n",
    "    ax[0, 2].set_ylim((0, 1))\n",
    "    ax[1, 1].set_ylim((0, 1))\n",
    "    ax[1, 2].set_ylim((0, 1))\n",
    "\n",
    "    # Create patches for the legend\n",
    "    patches = []\n",
    "    for i, learner in enumerate(results.keys()):\n",
    "        patches.append(mpatches.Patch(color = colors[i], label = learner))\n",
    "    plt.legend(handles = patches, bbox_to_anchor = (-.80, 2.53), \\\n",
    "               loc = 'upper center', borderaxespad = 0., ncol = 3, fontsize = 'x-large')\n",
    "    \n",
    "    # Aesthetics\n",
    "    plt.suptitle(\"Performance Metrics for Three Supervised Learning Models\", fontsize = 16, y = 1.10)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_A = GaussianNB()\n",
    "clf_B = RandomForestClassifier(random_state=50)\n",
    "clf_C = SVC(random_state=50)\n",
    "clf_D = DecisionTreeClassifier(random_state = 50)\n",
    "clf_E = AdaBoostClassifier(random_state =50)\n",
    "\n",
    "samples_50 = int((1/2) * len(y_train))\n",
    "samples_75 = int((75/100) * len(y_train))\n",
    "samples_100 = len(y_train)\n",
    "\n",
    "results = {}\n",
    "\n",
    "for clf in [ clf_B, clf_C, clf_E]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    results[clf_name] = {}\n",
    "    for i, samples in enumerate([samples_50, samples_75, samples_100]):\n",
    "        results[clf_name][i] = \\\n",
    "        train_predict(clf, samples, X_train, y_train, X_test, y_test)\n",
    "        \n",
    "#print (results)\n",
    "# Run metrics visualization for the supervised learning models chosen\n",
    "evaluate(results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
